{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv('/home/oarga/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "path_kg = \"ontorag copy/src/OntoGen/SACs/GraphRAGqa/answers_GraphRAG_KG.json\"\n",
    "path_kg_onto = \"ontorag copy/src/OntoGen/SACs/GraphRAGqa/answers_GraphRAG_KG_Ontology.json\"\n",
    "\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"anthropic/claude-3.5-sonnet\"\n",
    "TEMPERATURE = 0\n",
    "\n",
    "criteria = [\n",
    "    \"Comprehensiveness: How much detail does the answer provide to cover all aspects and details of the question?\",\n",
    "    \"Diversity: How varied and rich is the answer in providing different perspectives and insights on the question?\",\n",
    "    \"Empowerment: How well does the answer help the reader understand and make informed judgements about the topic?\",\n",
    "    \"Directness: How specifically and clearly does the answer address the question?\",\n",
    "]\n",
    "CRITERIA = (\n",
    "    3  # 0: Comprehensiveness, 1: Diversity, 2: Empowerment, 3: Directness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kg = json.load(open(path_kg))\n",
    "data_onto = json.load(open(path_kg_onto))\n",
    "\n",
    "for i in range(len(data_kg)):\n",
    "\n",
    "    print(\"=\" * 50, \" QUESTION \", i, \"=\" * 50)\n",
    "    print()\n",
    "    res = data_kg[i][0].split(\"\\n\")\n",
    "    res = [\"\\t\" + x for x in res if x]\n",
    "    res = \"\\n\".join(res)\n",
    "    print(res)\n",
    "    print()\n",
    "    print(\"=\" * 50, \" ANSWER 1 (GRAPHRAG KG)\", \"=\" * 50)\n",
    "    print()\n",
    "    res = data_kg[i][1].split(\"\\n\")\n",
    "    res = [\"\\t\" + x for x in res if x]\n",
    "    res = \"\\n\".join(res)\n",
    "    print(res)\n",
    "    print()\n",
    "    print(\"=\" * 50, \" ANSWER 2 (GRAPHRAG KG + ONTOLOGY)\", \"=\" * 50)\n",
    "    print()\n",
    "    res = data_onto[i][1].split(\"\\n\")\n",
    "    res = [\"\\t\" + x for x in res if x]\n",
    "    res = \"\\n\".join(res)\n",
    "    print(res)\n",
    "    print()\n",
    "    print(\"*\" * 140)\n",
    "    print(\"*\" * 140)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def query_oai(model, prompt, base_url):\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Given the question and answers below, and given the following criteria: \n",
    "{CRITERIA}, \n",
    "which of the two answers is better according to the criteria, \"ANSWER1\" or \"ANSWER2\"? \n",
    "Justify your answer and then answer with \" Winner=ANSWER1\" or \"Winner=ANSWER2\"\n",
    "If both answers are equally good, answer with \"Winner=None\".\n",
    "\n",
    "QUESTION: {QUESTION}\n",
    "\n",
    "========================================= ANSWER 1 =========================================\n",
    "\n",
    "{ANSWER1}\n",
    "\n",
    "========================================= ANSWER 2 =========================================\n",
    "\n",
    "{ANSWER2}\n",
    "\"\"\"\n",
    "\n",
    "answers = []\n",
    "for i in range(len(data_kg)):\n",
    "\n",
    "    print(\"Processing question \", i)\n",
    "\n",
    "    question = data_kg[i][0]\n",
    "    answer1 = data_kg[i][1]\n",
    "    answer2 = data_onto[i][1]\n",
    "\n",
    "    formated = prompt.format(\n",
    "        CRITERIA=criteria[CRITERIA],\n",
    "        QUESTION=question,\n",
    "        ANSWER1=answer1,\n",
    "        ANSWER2=answer2,\n",
    "    )\n",
    "    #ans = query_anthropic(client, formated)\n",
    "    ans = query_oai(MODEL, formated, 'https://openrouter.ai/api/v1')\n",
    "    if (\n",
    "        \"Winner=ANSWER2\".lower() in ans.lower()\n",
    "        and \"Winner=ANSWER1\".lower() not in ans.lower()\n",
    "    ):\n",
    "        answers.append(2)\n",
    "    elif (\n",
    "        \"Winner=ANSWER1\".lower() in ans.lower()\n",
    "        and \"Winner=ANSWER2\".lower() not in ans.lower()\n",
    "    ):\n",
    "        answers.append(1)\n",
    "    else:\n",
    "        answers.append(0)\n",
    "    print(formated)\n",
    "    print(ans)\n",
    "    print(\"Answer: \", answers)\n",
    "\n",
    "winner_kg = [a == 1 for a in answers].count(True)\n",
    "winner_onto = [a == 2 for a in answers].count(True)\n",
    "no_winner = [a == 0 for a in answers].count(True)\n",
    "\n",
    "print(\"Number of times GraphRAG KG won: \", winner_kg)\n",
    "print(\"Number of times GraphRAG KG + Ontology won: \", winner_onto)\n",
    "print(\"Number of times there was no clear winner: \", no_winner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
